{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import os \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs_path = 'public_tests/splitted/train/images'\n",
    "test_imgs_path = 'public_tests/splitted/test/images'\n",
    "train_gt_path = 'public_tests/splitted/train/gt.csv'\n",
    "test_gt_path = 'public_tests/splitted/test/gt.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  68%|██████▊   | 102/151 [00:52<00:25,  1.94it/s, v_num=29, train_loss_step=30.90, train_loss_epoch=54.80]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\venvs\\CV\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                | Params\n",
      "----------------------------------------------\n",
      "0 | model | FacesPointsDetector | 1.7 M \n",
      "----------------------------------------------\n",
      "1.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 M     Total params\n",
      "6.767     Total estimated model params size (MB)\n",
      "d:\\venvs\\CV\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 151/151 [00:46<00:00,  3.26it/s, v_num=30, loss_step=71.30, loss_epoch=145.0]Epoch 0, Train_loss: 144.266\n",
      "Epoch 1: 100%|██████████| 151/151 [00:48<00:00,  3.12it/s, v_num=30, loss_step=17.10, loss_epoch=51.40]Epoch 1, Train_loss: 51.168\n",
      "Epoch 2: 100%|██████████| 151/151 [00:47<00:00,  3.17it/s, v_num=30, loss_step=39.30, loss_epoch=37.70]Epoch 2, Train_loss: 37.71\n",
      "Epoch 3: 100%|██████████| 151/151 [00:50<00:00,  2.98it/s, v_num=30, loss_step=26.00, loss_epoch=32.10]Epoch 3, Train_loss: 32.066\n",
      "Epoch 4: 100%|██████████| 151/151 [00:48<00:00,  3.08it/s, v_num=30, loss_step=35.30, loss_epoch=30.00]Epoch 4, Train_loss: 29.993\n",
      "Epoch 5: 100%|██████████| 151/151 [00:50<00:00,  2.98it/s, v_num=30, loss_step=11.00, loss_epoch=26.70]Epoch 5, Train_loss: 26.626\n",
      "Epoch 6: 100%|██████████| 151/151 [00:54<00:00,  2.76it/s, v_num=30, loss_step=17.40, loss_epoch=25.60]Epoch 6, Train_loss: 25.524\n",
      "Epoch 7: 100%|██████████| 151/151 [00:50<00:00,  3.01it/s, v_num=30, loss_step=9.940, loss_epoch=24.40]Epoch 7, Train_loss: 24.313\n",
      "Epoch 8: 100%|██████████| 151/151 [00:50<00:00,  3.01it/s, v_num=30, loss_step=8.560, loss_epoch=22.90]Epoch 8, Train_loss: 22.786\n",
      "Epoch 9: 100%|██████████| 151/151 [00:49<00:00,  3.06it/s, v_num=30, loss_step=20.90, loss_epoch=22.50]Epoch 9, Train_loss: 22.453\n",
      "Epoch 10: 100%|██████████| 151/151 [00:50<00:00,  3.00it/s, v_num=30, loss_step=50.50, loss_epoch=21.80]Epoch 10, Train_loss: 21.997\n",
      "Epoch 11: 100%|██████████| 151/151 [00:51<00:00,  2.91it/s, v_num=30, loss_step=19.80, loss_epoch=20.60]Epoch 11, Train_loss: 20.623\n",
      "Epoch 12: 100%|██████████| 151/151 [00:50<00:00,  2.96it/s, v_num=30, loss_step=16.70, loss_epoch=20.40]Epoch 12, Train_loss: 20.373\n",
      "Epoch 13: 100%|██████████| 151/151 [00:49<00:00,  3.06it/s, v_num=30, loss_step=25.00, loss_epoch=19.30]Epoch 13, Train_loss: 19.325\n",
      "Epoch 14: 100%|██████████| 151/151 [00:48<00:00,  3.14it/s, v_num=30, loss_step=49.60, loss_epoch=19.80]Epoch 14, Train_loss: 19.964\n",
      "Epoch 15: 100%|██████████| 151/151 [00:46<00:00,  3.23it/s, v_num=30, loss_step=65.80, loss_epoch=20.10]Epoch 15, Train_loss: 20.42\n",
      "Epoch 16: 100%|██████████| 151/151 [00:46<00:00,  3.24it/s, v_num=30, loss_step=89.40, loss_epoch=19.40]Epoch 16, Train_loss: 19.804\n",
      "Epoch 17: 100%|██████████| 151/151 [00:46<00:00,  3.23it/s, v_num=30, loss_step=78.40, loss_epoch=19.50]Epoch 17, Train_loss: 19.881\n",
      "Epoch 18: 100%|██████████| 151/151 [00:46<00:00,  3.23it/s, v_num=30, loss_step=20.60, loss_epoch=17.20]Epoch 18, Train_loss: 17.257\n",
      "Epoch 19: 100%|██████████| 151/151 [00:46<00:00,  3.22it/s, v_num=30, loss_step=12.50, loss_epoch=16.00]Epoch 19, Train_loss: 15.951\n",
      "Epoch 20: 100%|██████████| 151/151 [00:47<00:00,  3.19it/s, v_num=30, loss_step=9.070, loss_epoch=15.20]Epoch 20, Train_loss: 15.205\n",
      "Epoch 21: 100%|██████████| 151/151 [00:46<00:00,  3.28it/s, v_num=30, loss_step=31.00, loss_epoch=15.50]Epoch 21, Train_loss: 15.631\n",
      "Epoch 22: 100%|██████████| 151/151 [00:46<00:00,  3.24it/s, v_num=30, loss_step=10.50, loss_epoch=16.30]Epoch 22, Train_loss: 16.295\n",
      "Epoch 23: 100%|██████████| 151/151 [00:46<00:00,  3.24it/s, v_num=30, loss_step=10.00, loss_epoch=14.50]Epoch 23, Train_loss: 14.498\n",
      "Epoch 24: 100%|██████████| 151/151 [00:46<00:00,  3.23it/s, v_num=30, loss_step=23.60, loss_epoch=14.60]Epoch 24, Train_loss: 14.657\n",
      "Epoch 25: 100%|██████████| 151/151 [00:48<00:00,  3.13it/s, v_num=30, loss_step=24.90, loss_epoch=15.30]Epoch 25, Train_loss: 15.405\n",
      "Epoch 26: 100%|██████████| 151/151 [00:49<00:00,  3.05it/s, v_num=30, loss_step=9.600, loss_epoch=14.80]Epoch 26, Train_loss: 14.745\n",
      "Epoch 27: 100%|██████████| 151/151 [00:50<00:00,  2.98it/s, v_num=30, loss_step=6.470, loss_epoch=14.40]Epoch 27, Train_loss: 14.326\n",
      "Epoch 28: 100%|██████████| 151/151 [00:49<00:00,  3.07it/s, v_num=30, loss_step=30.10, loss_epoch=15.00]Epoch 28, Train_loss: 15.094\n",
      "Epoch 29: 100%|██████████| 151/151 [00:53<00:00,  2.82it/s, v_num=30, loss_step=35.90, loss_epoch=14.80]Epoch 29, Train_loss: 14.948\n",
      "Epoch 30: 100%|██████████| 151/151 [00:53<00:00,  2.80it/s, v_num=30, loss_step=7.610, loss_epoch=16.00]Epoch 30, Train_loss: 15.903\n",
      "Epoch 31: 100%|██████████| 151/151 [00:49<00:00,  3.05it/s, v_num=30, loss_step=22.60, loss_epoch=13.80]Epoch 31, Train_loss: 13.833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=32` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 151/151 [00:49<00:00,  3.03it/s, v_num=30, loss_step=22.60, loss_epoch=13.80]\n"
     ]
    }
   ],
   "source": [
    "model = detection.train_detector(train_gt=train_gt_path, train_img_dir=train_imgs_path, fast_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of detection failed: Traceback (most recent call last):\n",
      "  File \"d:\\venvs\\CV\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"d:\\venvs\\CV\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\ProgramData\\Python3_64\\lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 879, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1017, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 947, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"d:\\SCIENCE, BITCH\\IT\\CV\\task7\\detection.py\", line 186\n",
      "    lr_scheduler = \n",
      "                   ^\n",
      "SyntaxError: invalid syntax\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# chkpt_path ='lightning_logs/version_18/checkpoints/epoch=15-step=4800.ckpt' #lightning_logs/version_17/checkpoints/epoch=15-step=4800.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(current_shape, labels):\n",
    "    x_scale = 100/current_shape[2]\n",
    "    y_scale = 100/current_shape[1]\n",
    "    transformed = labels.clone()\n",
    "    for i in range(len(labels)):\n",
    "        if i % 2 == 0:\n",
    "            scale = x_scale\n",
    "        else:\n",
    "            scale = y_scale\n",
    "        transformed[i] = int(transformed[i]*scale)\n",
    "    return transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_err(test_imgs_dir, test_gt_path, model):\n",
    "    err = 0.0\n",
    "    dataset = detection.FacesPointsDataset(test_imgs_dir, test_gt_path, mode='test', transform=None)\n",
    "    for i in range(len(dataset)):\n",
    "        img, label = dataset[i]\n",
    "        pred = model(img[None,:]).detach()[0]\n",
    "        # result[dataset.items[i][0]] = pred\n",
    "        diff = ((pred - label)**2).mean()\n",
    "        err += diff\n",
    "    err /= len(dataset)\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.8981)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_test_err(test_imgs_path, test_gt_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
